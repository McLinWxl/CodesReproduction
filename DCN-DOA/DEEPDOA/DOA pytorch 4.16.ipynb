{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ethical-subsection",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mclinwong/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worst-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "matpath = '/Users/mclinwong/GitHub/CodesReproduction/DCN-DOA/Data/matlib/'\n",
    "read_temp=scipy.io.loadmat(matpath + 'data2_trainlow.mat')\n",
    "S_est=read_temp['S_est']                   #shape:(19800, 120, 2)\n",
    "#S_abs=read_temp['S_abs']                   #shape:(19800,240)\n",
    "S_label=read_temp['S_label']               #(19800,120)                     \n",
    "S_label1 = np.expand_dims(S_label, 2)      #(19800,120,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neural-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch=300\n",
    "batch_size=120\n",
    "batch_size_test = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "institutional-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepted-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_est_train, S_est_test, S_label1_train, S_label1_test = train_test_split(S_est, S_label1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agricultural-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将训练集和测试集转为Tensor形式，并交换后两维度次序\n",
    "S_label1_trainTH = torch.Tensor(S_label1_train).permute(0,2,1)\n",
    "S_label1_testTH = torch.Tensor(S_label1_test).permute(0,2,1)\n",
    "S_est_trainTH = torch.Tensor(S_est_train).permute(0,2,1)\n",
    "S_est_testTH = torch.Tensor(S_est_test).permute(0,2,1)\n",
    "\n",
    "S_est_trainTH = S_est_trainTH.to(device)\n",
    "S_est_testTH = S_est_testTH.to(device)\n",
    "S_label1_trainTH = S_label1_trainTH.to(device) \n",
    "S_label1_testTH = S_label1_testTH.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "manufactured-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据和标签一一对应\n",
    "a = ()\n",
    "for i in range(0,15840):\n",
    "    a += ((S_est_trainTH[i], S_label1_trainTH[i]),)\n",
    "\n",
    "b = ()\n",
    "for i in range(0,3960):\n",
    "    b += ((S_est_testTH[i], S_label1_testTH[i]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "remarkable-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(a, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(b, batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "forbidden-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN网络结构\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,activ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(2,12,kernel_size=25, padding=12), nn.BatchNorm1d(12), activ())\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(12,6,kernel_size=15, padding=7),  nn.BatchNorm1d(6), activ())\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(6,3,kernel_size=5, padding=2), nn.BatchNorm1d(3), activ())\n",
    "        self.conv4 = nn.Sequential(nn.Conv1d(3,1,kernel_size=3, padding=1),nn.BatchNorm1d(1), activ())\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "       \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "matched-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(2,12,kernel_size=25, padding=12), nn.BatchNorm1d(12))\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(12,6,kernel_size=15, padding=7),  nn.BatchNorm1d(6))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(6,3,kernel_size=5, padding=2), nn.BatchNorm1d(3))\n",
    "        self.conv4 = nn.Sequential(nn.Conv1d(3,1,kernel_size=3, padding=1),nn.BatchNorm1d(1))\n",
    "        self.trans1 = nn.Conv1d(2,6,kernel_size=1, padding=0)\n",
    "        self.trans2 = nn.Conv1d(6,1,kernel_size=1, padding=0)\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        y1 = F.relu(self.conv1(x))\n",
    "        y2 = F.relu(self.trans1(x) + self.conv2(y1))\n",
    "        y3 = F.relu(self.conv3(y2))\n",
    "        y4 = F.relu(self.trans2(y2)+self.conv4(y3))\n",
    "       \n",
    "        return y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assisted-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigth_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        init.kaiming_uniform_(m.weight.data)\n",
    "        init.constant_(m.bias.data,0.1)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "#   elif isinstance(m, nn.Linear):\n",
    "#      m.weight.data.normal_(0,0.01)\n",
    "#       m.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "frank-quilt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(2, 12, kernel_size=(25,), stride=(1,), padding=(12,))\n",
       "    (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(12, 6, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "    (1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(6, 3, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv1d(3, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_relu = CNN(nn.ReLU).to(device)\n",
    "cnn_tanh = CNN(nn.Tanh).to(device)\n",
    "cnn_sigmoid = CNN(nn.Sigmoid).to(device)\n",
    "cnn_relu_resnet = CNN_resnet().to(device)\n",
    "cnn_tanh_resnet = CNN_resnet().to(device)\n",
    "cnn_sigmoid_resnet = CNN_resnet().to(device)\n",
    "\n",
    "\n",
    "\n",
    "cnn_relu.apply(weigth_init)\n",
    "#cnn_tanh.apply(weigth_init)\n",
    "#cnn_sigmoid.apply(weigth_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confident-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "charming-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练过程\n",
    "\n",
    "def train(epoch, model):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "   \n",
    "    for  batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "#        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "    print('Train Epoch: {} \\tloss: {:.4f}'.format(\n",
    "                epoch+1, loss.item()\n",
    "            ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "grateful-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rmse(model):\n",
    "    \n",
    "    a = 0\n",
    "    \n",
    "    for (data,label) in test_loader: \n",
    "        c = model(data)\n",
    "        c1 = c.cpu().detach()\n",
    "        labe = label.cpu()\n",
    "        \n",
    "        for i in range(0, 60):\n",
    "            bias = c1[i,0] - labe[i,0]\n",
    "            bias_norm = torch.norm(bias, p=1)\n",
    "            bias_norm_sqr = torch.pow(bias_norm,2)\n",
    "            a += bias_norm_sqr\n",
    "            \n",
    "    \n",
    "    RMSE = torch.sqrt(a/(3960*2))\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bright-header",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m cnnrele_loss_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m300\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     cnn_loss \u001b[39m=\u001b[39m train(epoch, cnn_relu)\n\u001b[1;32m      5\u001b[0m     cnnrele_loss_list\u001b[39m.\u001b[39mappend(cnn_loss)\n\u001b[1;32m      7\u001b[0m test_rmse(cnn_relu)\n",
      "Cell \u001b[0;32mIn [14], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, model)\u001b[0m\n\u001b[1;32m     14\u001b[0m     output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     16\u001b[0m     loss \u001b[39m=\u001b[39m loss_func(output, target)\n\u001b[0;32m---> 17\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/_tensor.py:473\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    464\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    465\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    466\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    471\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[0;32m--> 473\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    474\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    475\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#cnn+relu\n",
    "cnnrele_loss_list = []\n",
    "for epoch in range(0,300):\n",
    "    cnn_loss = train(epoch, cnn_relu)\n",
    "    cnnrele_loss_list.append(cnn_loss)\n",
    "      \n",
    "test_rmse(cnn_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(nb_epoch), train_loss, label='train loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn+tanh\n",
    "for epoch in range(0,300):\n",
    "    \n",
    "    train(epoch, cnn_tanh)\n",
    "    \n",
    "test_rmse(cnn_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn+sigmoid\n",
    "for epoch in range(0,300):\n",
    "    \n",
    "    train(epoch, cnn_sigmoid)\n",
    "    \n",
    "test_rmse(cnn_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-bermuda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cnn+relu+resnet\n",
    "for epoch in range(0,300):\n",
    "    \n",
    "    train(epoch, cnn_relu_resnet)\n",
    "    \n",
    "test_rmse(cnn_relu_resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_temp=scipy.io.loadmat(r\"C:\\Users\\Administrator\\Desktop\\DEEPDOA\\code\\data2test\\data2_test.mat\")\n",
    "K=2\n",
    "k=1\n",
    "\n",
    "S_est=read_temp['S_est']\n",
    "S_label=read_temp['S_label']\n",
    "R_est=read_temp['R_est']\n",
    "DOA_train=read_temp['DOA_train']\n",
    "theta=read_temp['theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_est_TH = torch.Tensor(S_est).permute(0,2,1)\n",
    "S_est_TH = S_est_TH.to(device)\n",
    "S_label_TH = torch.Tensor(S_label)\n",
    "\n",
    "a = cnn_relu(S_est_TH)\n",
    "a_1 = a[1,0]\n",
    "a_2 = np.array(a_1.cpu().detach())\n",
    "DCN1=np.zeros((120))\n",
    "DCN1[:]=a_2\n",
    "\n",
    "b = cnn_tanh(S_est_TH)\n",
    "b_1 = b[1,0]\n",
    "b_2 = np.array(b_1.cpu().detach())\n",
    "DCN2=np.zeros((120))\n",
    "DCN2[:]=b_2\n",
    "\n",
    "c = cnn_sigmoid(S_est_TH)\n",
    "c_1 = c[1,0]\n",
    "c_2 = np.array(c_1.cpu().detach())\n",
    "DCN3=np.zeros((120))\n",
    "DCN3[:]=c_2\n",
    "\n",
    "d = cnn_relu_resnet(S_est_TH)\n",
    "d_1 = d[1,0]\n",
    "d_2 = np.array(d_1.cpu().detach())\n",
    "DCN4=np.zeros((120))\n",
    "DCN4[:]=d_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif']=['Microsoft YaHei']\n",
    "figsize = 15,3\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(theta.T,(DCN1[:]),linewidth=2.0)\n",
    "plt.ylim([-0.1,0.8])\n",
    "plt.plot(DOA_train[:,k],np.ones((K,))*0.6,'rD')\n",
    "plt.tick_params(labelsize=13)\n",
    "plt.xlabel('到达波方向($^o$)')\n",
    "plt.ylabel('频 谱') \n",
    "plt.legend([\"relu\"],loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(theta.T,(DCN2[:]),linewidth=2.0)\n",
    "plt.ylim([-0.1,0.8])\n",
    "plt.plot(DOA_train[:,k],np.ones((K,))*0.6,'rD')\n",
    "plt.tick_params(labelsize=13)\n",
    "#labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "plt.xlabel('到达波方向($^o$)')\n",
    "plt.legend([\"tanh\"],loc='upper left')\n",
    "#plt.ylabel('频 谱') \n",
    "#plt.show()\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(theta.T,(DCN3[:]),linewidth=2.0)\n",
    "plt.ylim([-0.1,0.8])\n",
    "plt.plot(DOA_train[:,k],np.ones((K,))*0.6,'rD')\n",
    "plt.tick_params(labelsize=13)\n",
    "#labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "plt.xlabel('到达波方向($^o$)')\n",
    "#plt.ylabel('频 谱') \n",
    "plt.legend([\"sigmoid\"],loc='upper left')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = 10,3\n",
    "figure, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(theta.T,(DCN1[:]),linewidth=2.0)\n",
    "plt.ylim([-0.1,0.8])\n",
    "plt.plot(DOA_train[:,k],np.ones((K,))*0.6,'rD')\n",
    "plt.tick_params(labelsize=13)\n",
    "plt.xlabel('到达波方向($^o$)')\n",
    "plt.ylabel('频 谱') \n",
    "plt.legend([\"CNN+relu\"],loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(theta.T,(DCN4[:]),linewidth=2.0)\n",
    "plt.ylim([-0.1,0.8])\n",
    "plt.plot(DOA_train[:,k],np.ones((K,))*0.6,'rD')\n",
    "plt.tick_params(labelsize=13)\n",
    "#labels = ax.get_xticklabels() + ax.get_yticklabels()\n",
    "plt.xlabel('到达波方向($^o$)')\n",
    "plt.legend([\"ResNet+relu\"],loc='upper left')\n",
    "#plt.ylabel('频 谱') \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-twist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b2b9bf415f84b889e420ad7a8860db48801ef28c10f7deabf8a2d1409fae0b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
