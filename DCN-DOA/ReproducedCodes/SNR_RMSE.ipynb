{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mclinwong/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import heapq\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices: cpu\n"
     ]
    }
   ],
   "source": [
    "#inisialize\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f'Devices: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 1000, I: 120, c: 56\n",
      "S_est: (1000, 2, 120, 31), S_abs: (1000, 240, 31) \n",
      "S_label: (1000, 120, 31),\n",
      "S_label1: (1000, 120, 1, 31) ,\n",
      "R_est: (1000, 56, 31)\n"
     ]
    }
   ],
   "source": [
    "#read file and load models path\n",
    "h5path = '/Users/mclinwong/GitHub/CodesReproduction/DCN-DOA/Data/h5/'\n",
    "pthpath = '/Users/mclinwong/GitHub/CodesReproduction/DCN-DOA/Data/pth/'\n",
    "#read mat file\n",
    "matpath = '/Users/mclinwong/GitHub/CodesReproduction/DCN-DOA/Data/matlib/'\n",
    "figurepath = '/Users/mclinwong/GitHub/CodesReproduction/DCN-DOA/ReproducedCodes/Figures/'\n",
    "read_temp=scipy.io.loadmat(matpath + 'data2_snr.mat')\n",
    "T_SBC_R=read_temp['T_SBC_R']\n",
    "T_SBC=read_temp['T_SBC']\n",
    "SNR=read_temp['SNR']\n",
    "S_est=read_temp['S_est']\n",
    "S_est = S_est.transpose(0, 2, 1, 3)\n",
    "[r2, K, I, S] = np.shape(S_est)\n",
    "S_abs = np.zeros((r2, I*2, S))\n",
    "for i in range(r2):\n",
    "    for k in range(S):\n",
    "        for j in range(I):\n",
    "            S_abs[i, j, k] = S_est[i, 0, j, k]\n",
    "            S_abs[i, I+j, k] = S_est[i, 1, j, k]    \n",
    "\n",
    "S_label=read_temp['S_label']\n",
    "R_est=read_temp['R_est']\n",
    "DOA_train=read_temp['DOA_train']\n",
    "theta=read_temp['theta']\n",
    "gamma=read_temp['gamma']\n",
    "gamma_R=read_temp['gamma_R']\n",
    "S_label1 = np.expand_dims(S_label, 2)\n",
    "normalizer = preprocessing.Normalizer().fit(R_est[:, :, 0])\n",
    "\n",
    "#r2 for the number of data\n",
    "#K for the number of sources\n",
    "#I for the number of DOAs\n",
    "#S for the number of SNRs\n",
    "\n",
    "[r2,c,S]=np.shape(R_est)\n",
    "[r2,I,S]=np.shape(S_label)\n",
    "print(f'r2: {r2}, I: {I}, c: {c}')\n",
    "print(f'S_est: {S_est.shape}, S_abs: {S_abs.shape} \\nS_label: {S_label.shape},\\nS_label1: {S_label1.shape} ,\\nR_est: {R_est.shape}')\n",
    "\n",
    "\n",
    "DOA = np.arange(I)-60\n",
    "L = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_ReLu(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ReLu, self).__init__()\n",
    "        self.cnn_1 = nn.Conv1d(in_channels=2, out_channels=12, kernel_size=25, padding=12)\n",
    "        self.cnn_2 = nn.Conv1d(in_channels=12, out_channels=6, kernel_size=15, padding=7)\n",
    "        self.cnn_3 = nn.Conv1d(in_channels=6, out_channels=3, kernel_size=5, padding=2)\n",
    "        self.cnn_4 = nn.Conv1d(in_channels=3, out_channels=1, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.cnn_1(x))\n",
    "        x = self.relu(self.cnn_2(x))\n",
    "        x = self.relu(self.cnn_3(x))\n",
    "        x = self.relu(self.cnn_4(x))\n",
    "        return x\n",
    "cnnrelu = torch.load(pthpath + 'cnnrelu.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_tanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_tanh, self).__init__()\n",
    "        self.cnn_1 = nn.Conv1d(in_channels=2, out_channels=12, kernel_size=25, padding=12)\n",
    "        self.cnn_2 = nn.Conv1d(in_channels=12, out_channels=6, kernel_size=15, padding=7)\n",
    "        self.cnn_3 = nn.Conv1d(in_channels=6, out_channels=3, kernel_size=5, padding=2)\n",
    "        self.cnn_4 = nn.Conv1d(in_channels=3, out_channels=1, kernel_size=3, padding=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        x = self.tanh(self.cnn_1(x))\n",
    "        x = self.tanh(self.cnn_2(x))\n",
    "        x = self.tanh(self.cnn_3(x))\n",
    "        x = self.tanh(self.cnn_4(x))\n",
    "        return x\n",
    "cnntanh = torch.load(pthpath + 'cnntanh.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_sigmoid, self).__init__()\n",
    "        self.cnn_1 = nn.Conv1d(in_channels=2, out_channels=12, kernel_size=25, padding=12)\n",
    "        self.cnn_2 = nn.Conv1d(in_channels=12, out_channels=6, kernel_size=15, padding=7)\n",
    "        self.cnn_3 = nn.Conv1d(in_channels=6, out_channels=3, kernel_size=5, padding=2)\n",
    "        self.cnn_4 = nn.Conv1d(in_channels=3, out_channels=1, kernel_size=3, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.cnn_1(x))\n",
    "        x = self.sigmoid(self.cnn_2(x))\n",
    "        x = self.sigmoid(self.cnn_3(x))\n",
    "        x = self.sigmoid(self.cnn_4(x))\n",
    "        return x\n",
    "cnnsigmoid = torch.load(pthpath + 'cnnsigmoid.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_ReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_ReLU, self).__init__()\n",
    "        self.fc1 = nn.Linear(2*L, int(2*L/3))\n",
    "        self.fc2 = nn.Linear(int(2*L/3), int(4*L/9))\n",
    "        self.fc3 = nn.Linear(int(4*L/9), int(2*L/3))\n",
    "        self.fc4 = nn.Linear(int(2*L/3), L)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        return x\n",
    "dnnrelu = torch.load(pthpath + 'dnnrelu.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_Tanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_Tanh, self).__init__()\n",
    "        self.fc1 = nn.Linear(2*L, int(2*L/3))\n",
    "        self.fc2 = nn.Linear(int(2*L/3), int(4*L/9))\n",
    "        self.fc3 = nn.Linear(int(4*L/9), int(2*L/3))\n",
    "        self.fc4 = nn.Linear(int(2*L/3), L)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        x = self.tanh(self.fc1(x))\n",
    "        x = self.tanh(self.fc2(x))\n",
    "        x = self.tanh(self.fc3(x))\n",
    "        x = self.tanh(self.fc4(x))\n",
    "        return x\n",
    "dnntanh = torch.load(pthpath + 'dnntanh.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_Sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_Sigmoid, self).__init__()\n",
    "        self.fc1 = nn.Linear(2*L, int(2*L/3))\n",
    "        self.fc2 = nn.Linear(int(2*L/3), int(4*L/9))\n",
    "        self.fc3 = nn.Linear(int(4*L/9), int(2*L/3))\n",
    "        self.fc4 = nn.Linear(int(2*L/3), L)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "dnnsigmoid = torch.load(pthpath + 'dnnsigmoid.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(model, inputx, k, flag):\n",
    "    #flag==0 for CNN, flag==1 for DNN\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    ls = []\n",
    "    for i in range(r2):\n",
    "        with torch.no_grad():\n",
    "            if flag==0:\n",
    "                x = torch.from_numpy(inputx[i,:,:,k]).float().to(device)\n",
    "            if flag==1:\n",
    "                x = torch.from_numpy(inputx[i,:,k]).float().to(device)\n",
    "            x = x.to(device)\n",
    "            y = model(x)\n",
    "            y = y.cpu().numpy()\n",
    "            ls.append(y)\n",
    "    predict = np.array(ls)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DOAPredict(predict, flag, height = 0.1, nodetect = -200):\n",
    "    #flag==0 for CNN, flag==1 for DNN\n",
    "    peak = np.zeros((K, r2))\n",
    "    for i in range(r2):\n",
    "        if flag==0: #CNN\n",
    "            li = predict[i,0,:]\n",
    "        if flag==1: #DNN\n",
    "            li = predict[i,:]\n",
    "        peaks_st = np.zeros((K))\n",
    "        peaks_st = peaks_st + nodetect\n",
    "        peaks,_ = scipy.signal.find_peaks(li, height=height)\n",
    "        maxamp = heapq.nlargest(K, li[peaks])\n",
    "        rank = np.zeros(np.shape(maxamp)[0])\n",
    "        for s in range(np.shape(maxamp)[0]):\n",
    "            rank[s] = np.where(li==maxamp[s])[0].item()\n",
    "        \n",
    "        if len(peaks) == K:\n",
    "            peaks_st = peaks\n",
    "        elif len(peaks) == 0:\n",
    "            peaks_st = peaks_st\n",
    "        elif len(peaks) < K:\n",
    "            for t in range(len(peaks)):\n",
    "                peaks_st[t] = peaks[t]\n",
    "        elif len(peaks) > K:\n",
    "            for j in range(K):\n",
    "                peaks_st[j] = rank[j]\n",
    "\n",
    "        peak[:,i] = sorted(peaks_st, reverse=True)\n",
    "        # if peaks_st[0] > peaks_st[1]:\n",
    "        #     peak[:,i] = [peaks_st[0], peaks_st[1]]\n",
    "        # else:\n",
    "        #     peak[:,i] = [peaks_st[1], peaks_st[0]]\n",
    "    return peak-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Test() missing 1 required positional argument: 'flag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predict_cnntanh \u001b[39m=\u001b[39m Test(cnntanh, S_est, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m doa_cnntanh \u001b[39m=\u001b[39m DOAPredict(predict_cnntanh, \u001b[39m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m predict_cnnrelu \u001b[39m=\u001b[39m Test(cnnrelu, S_est, \u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Test() missing 1 required positional argument: 'flag'"
     ]
    }
   ],
   "source": [
    "# predict_cnntanh = Test(cnntanh, S_est, 0)\n",
    "# doa_cnntanh = DOAPredict(predict_cnntanh, 0)\n",
    "# predict_cnnrelu = Test(cnnrelu, S_est, 0)\n",
    "# doa_cnnrelu = DOAPredict(predict_cnnrelu, 0)\n",
    "# predict_cnnsigmoid = Test(cnnsigmoid, S_est, 0)\n",
    "# doa_cnnsigmoid = DOAPredict(predict_cnnsigmoid, 0)\n",
    "\n",
    "# predict_dnntanh = Test(dnntanh, S_abs, 1)\n",
    "# doa_dnntanh = DOAPredict(predict_dnntanh, 1)\n",
    "# predict_dnnrelu = Test(dnnrelu, S_abs, 1)\n",
    "# doa_dnnrelu = DOAPredict(predict_dnnrelu,1)\n",
    "# predict_dnnsigmoid = Test(dnnsigmoid, S_abs, 1)\n",
    "# doa_dnnsigmoid = DOAPredict(predict_dnnsigmoid, 1)\n",
    "\n",
    "# doa_sbl = DOAPredict(gamma, 1)\n",
    "# doa_sblr = DOAPredict(gamma_R, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnn_low=np.zeros((r2,1))\n",
    "#change the column\n",
    "def switchcolumn(inarray):\n",
    "    a = np.zeros((K, r2))\n",
    "    a[0,:] = inarray[1,:]\n",
    "    a[1,:] = inarray[0,:]\n",
    "    return a\n",
    "\n",
    "def predict2doa(model, input, flag):\n",
    "    predict = np.zeros((r2, I, S))\n",
    "    for i in range(S):\n",
    "        predict1 = Test(model, input, i, flag)\n",
    "        predict[:, :, i] = predict1\n",
    "    return predict\n",
    "\n",
    "def caculate_error(predict):\n",
    "    rmse_list = []\n",
    "    for k in range(S):\n",
    "        predict = Test(cnntanh, S_est, k, 0)\n",
    "        # predict = switchcolumn(predict)\n",
    "        for i in range(K):\n",
    "            rmse = np.mean(np.sqrt(predict[i,:]-DOA_train[i,:,k]))\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "# doa_dnntanh = predict2doa(dnntanh, S_abs, 1)\n",
    "doa_dcntanh = predict2doa(cnntanh, S_est, 0)\n",
    "\n",
    "# err_dnntanh = caculate_error(doa_dnntanh)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b2b9bf415f84b889e420ad7a8860db48801ef28c10f7deabf8a2d1409fae0b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
